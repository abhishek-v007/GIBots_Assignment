{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFGstdMe+qjmXWdP5XLuWV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishek-v007/GIBots_Assignment/blob/main/GIBOTS1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "l7QUky9g2yxi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the train.csv and trainLabels.csv files\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "train_labels_df = pd.read_csv(\"trainLabels.csv\")\n",
        "\n",
        "# Extract the text from the \"Content\" column\n",
        "texts = train_df[\"Content\"]\n",
        "\n",
        "# Create a bag of words\n",
        "vectorizer = CountVectorizer()\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "\n",
        "# Remove the np.nan values from the 'Content' column\n",
        "train_df = train_df.dropna(subset=['Content'])\n",
        "\n",
        "# Get the texts\n",
        "texts = train_df[\"Content\"]\n",
        "\n",
        "# Create the vectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer and transform the texts\n",
        "X = vectorizer.fit_transform(texts)\n",
        "# Use the bag of words as input to a logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Use the Hash field value as an additional feature\n",
        "X = X.toarray()\n",
        "X = pd.DataFrame(X, columns=vectorizer.get_feature_names_out())\n",
        "X[\"x5\"] = train_df[\"x5\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "-ajwkY3lTQyE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()"
      ],
      "metadata": {
        "id": "y7D_NUEfTR_A"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the labels\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "train_labels_df = label_encoder.fit_transform(train_df[\"x5\"])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x_3qhCnMQobE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training data\n",
        "X = X.dropna()\n",
        "import numpy as np\n",
        "train_labels_df = np.nan_to_num(train_labels_df)\n",
        "train_labels_df = train_labels_df[train_labels_df != 0]\n"
      ],
      "metadata": {
        "id": "s38RCy4BUQ4o"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of X:', X.shape)\n",
        "print('Shape of train_labels_df:', train_labels_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUV_jPKwXNJ8",
        "outputId": "f39c16a7-5c0d-499e-d630-e63af06e4a51"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (1732, 3097)\n",
            "Shape of train_labels_df: (2014,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace NaN values with 0 in X\n",
        "X = X.replace(np.nan, 0)\n",
        "\n",
        "\n",
        "\n",
        "# Convert train_labels_df to a 1D array\n",
        "train_labels_df = np.ravel(train_labels_df)"
      ],
      "metadata": {
        "id": "lpr1WeeFXSM0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of X: {X.shape}\")\n",
        "print(f\"Shape of train_labels_df: {train_labels_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U115MFqoYeWk",
        "outputId": "2e97086e-f921-4656-afc5-28cd4a764829"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (1732, 3097)\n",
            "Shape of train_labels_df: (2014,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"First 5 rows of X:\\n{X.head()}\")\n",
        "print(f\"\\nFirst 5 rows of train_labels_df:\\n{train_labels_df}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmfdNX_8Ygvo",
        "outputId": "68c392e6-bcb8-4f28-b707-e4689b84e6b7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of X:\n",
            "   01fua6sfh369yiv9fv  01ipzreo6eyu  04fgcrgjbzzzim5aiav  04jduy  \\\n",
            "0                   0             0                    0       0   \n",
            "2                   0             0                    0       0   \n",
            "3                   0             0                    0       0   \n",
            "4                   0             0                    0       0   \n",
            "5                   0             0                    0       0   \n",
            "\n",
            "   09dub06cruvptbuz0  09miiz3g  0a24tqcc8pfi7uctbcqxs7ggbldkesort6  \\\n",
            "0                  0         0                                   0   \n",
            "2                  0         0                                   0   \n",
            "3                  0         0                                   0   \n",
            "4                  0         0                                   0   \n",
            "5                  0         0                                   0   \n",
            "\n",
            "   0agopeiuvyvb6o  0b0aque12f67  0babsp2yxvc1l1saibfizeaszml  ...  \\\n",
            "0               0             0                            0  ...   \n",
            "2               0             0                            0  ...   \n",
            "3               0             0                            0  ...   \n",
            "4               0             0                            0  ...   \n",
            "5               0             0                            0  ...   \n",
            "\n",
            "   zy8gqgmfnypkmhdfy5fzuecm  zyb14qwpg7pcqinsasij3galmphfzev5fwc  \\\n",
            "0                         0                                    0   \n",
            "2                         0                                    0   \n",
            "3                         0                                    0   \n",
            "4                         0                                    0   \n",
            "5                         0                                    0   \n",
            "\n",
            "   zyf3snxtnnj0endaziqgh1uevpkppv0c  zyhhsh5iqg7b  zyp9pjhj71syaxra4a  zypvr  \\\n",
            "0                                 0             0                   0      0   \n",
            "2                                 0             0                   0      0   \n",
            "3                                 0             0                   0      0   \n",
            "4                                 0             0                   0      0   \n",
            "5                                 0             0                   0      0   \n",
            "\n",
            "   zz  zzcjk0qrtb1fez18wsrk0cd1tq  zzeixfnkat4w1oedximnkraey0ph41i00hpydo  \\\n",
            "0   0                           0                                       0   \n",
            "2   0                           0                                       0   \n",
            "3   0                           0                                       0   \n",
            "4   0                           0                                       0   \n",
            "5   0                           0                                       0   \n",
            "\n",
            "   zzvc2ccbuh  \n",
            "0           0  \n",
            "2           0  \n",
            "3           0  \n",
            "4           0  \n",
            "5           0  \n",
            "\n",
            "[5 rows x 3097 columns]\n",
            "\n",
            "First 5 rows of train_labels_df:\n",
            "[202 738 268 ... 562 130 430]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, train_labels_df)"
      ],
      "metadata": {
        "id": "mMM_0UfRUkA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test.csv file\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Extract the text from the \"Content\" column\n",
        "test_texts = test_df[\"Content\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "E6tRB5CdWlz4"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.dropna()\n",
        "test_texts = test_df[\"Content\"]\n",
        "test_X = vectorizer.transform(test_texts)\n",
        "test_X = test_X.toarray()\n"
      ],
      "metadata": {
        "id": "MELOGFNoaNLB"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bag of words for the test data\n",
        "test_X = vectorizer.transform(test_texts)\n",
        "test_X = test_X.toarray()\n",
        "test_X = pd.DataFrame(test_X, columns=vectorizer.get_feature_names_out())\n",
        "test_X[\"Hash\"] = test_df[\"Hash\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "zemFEdhrZWxy"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to predict the probabilities for the test data\n",
        "test_preds = model.predict_proba(test_X)"
      ],
      "metadata": {
        "id": "lHLtwDEEdbGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Format the predictions into the required submission format\n",
        "submission_df = pd.DataFrame(columns=[\"id_label\"] + [f\"{i}_y{j}\" for i in range(1, 6) for j in range(1, 6)])\n"
      ],
      "metadata": {
        "id": "Tux82VMQacIZ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test_preds)):\n",
        "    submission_df = submission_df.append({\n",
        "        \"id_label\": i,\n",
        "        **{f\"{i}_y{j}\": test_preds[i][j-1] for j in range(1,6)}\n",
        "    }, ignore_index=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "FyDDLxeseOFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "ENzal_NEeRTr"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the result"
      ],
      "metadata": {
        "id": "wzt4bLrwgYql"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}